checks:
  # --- R2: README Exists and is Well Detailed (0-1 pt) ---
  - name: "R2.1: README Exists and is Well Detailed"
    type: "ai_check"
    files_to_analyze: ["README.md"]
    per_file_char_limit: 6000
    total_context_char_limit: 6000
    prompt: >
      You are reviewing a BEGINNER Django project README.
      Scoring:
      - PASS: Has ALL THREE core elements: (1) project title/heading, (2) brief description of what it does, (3) basic install/run steps.
      - FAIL: Missing one or more of the three core elements.
      
      Improvement ideas (usage examples, contribution guide, etc.) are suggestions, not reasons for FAIL.

      Output format:
      PASS|FAIL - short reason
      Suggestions:
      - bullet 1
      - bullet 2

      CONTEXT (README.md):
      ---
      {context}
      ---

  - name: "R2.2: Project dependencies are properly managed"
    type: "file_exists"
    paths: ["requirements.txt", "Pipfile", "pyproject.toml"]
    recursive: true
    max_depth: 2

  # --- R3: Code is Clean, Readable and Well Structured (0-4 pts) ---
  - name: "R3.1: Code is Clean, Readable, and Well-Structured"
    type: "ai_check"
    files_to_analyze: ["views.py", "models.py", "serializers.py", "forms.py", "urls.py"]
    per_file_char_limit: 5000
    total_context_char_limit: 20000
    prompt: >
      Beginner Django code quality review.
      Check for: (1) Readability (clear naming), (2) Complexity (short functions, low nesting), (3) Duplication, (4) Structure (e.g., 'Fat Models, Skinny Views'), (5) URL Naming.

      Scoring (for a 0-4 pt scale):
      - PASS: Very clean. Good naming, low complexity, good structure. (Maps to 3-4 pts)
      - PARTIAL: Understandable, but 2-3 moderate issues (some vague names, 1-2 long/nested functions, some logic in views). (Maps to 1-2 pts)
      - FAIL: Multiple severe issues making code hard to follow (widespread unclear naming, high complexity, lots of logic in views). (Maps to 0 pts)
      
      Output:
      PASS|PARTIAL|FAIL - brief reason
      Improvements:
      - bullet 1
      - bullet 2
      - bullet 3 (max 5)

      CONTEXT:
      ---
      {context}
      ---

  - name: "R3.2: Basic security practices are followed (No hardcoded secrets)"
    type: "ai_check"
    files_to_analyze: ["settings.py"]
    per_file_char_limit: 6000
    total_context_char_limit: 6000
    prompt: >
      Environment variable and secret usage review.
      Scoring:
      - PASS: SECRET_KEY and DB credentials are NOT hardcoded. (They are loaded from env vars).
      - FAIL: SECRET_KEY or DB credentials (password) are plainly hardcoded.
      
      Output:
      PASS|FAIL - reason
      Suggestions:
      - bullet list (only if FAIL)

      CONTEXT:
      ---
      {context}
      ---

  - name: "R3.3: Sensitive files and virtual environments are ignored"
    type: "file_exists"
    path: ".gitignore"
    recursive: true

  - name: "R3.4: Example environment file present"
    type: "file_exists"
    paths: [".env.example", "example.env", "env.sample"]

  # --- R4: Git Properly Used (0-1 pt) ---
  - name: "R4.1: Git history is sufficient and meaningful"
    type: "ai_check"
    context_source: "git_log"
    git_log_depth: 40
    prompt: >
      Git log review (beginner). Check two things: 
      (1) Is there more than 3 commits?
      (2) Are the messages meaningful (not just "update", "fix")?
      
      Scoring:
      - PASS: Yes to both. History has > 3 commits AND the majority (>60%) are descriptive.
      - PARTIAL: Meets only one criteria (e.g., > 3 commits but all are meaningless, OR only 2-3 good commits).
      - FAIL: No to both. Very few commits (<=3) AND messages are meaningless.
      
      Output:
      PASS|PARTIAL|FAIL - short reason
      Suggestions:
      - bullet 1 (max 3)

      CONTEXT (GIT LOG):
      ---
      {context}
      ---

  # --- R5: Original Idea (0-1 pt) ---
  - name: "R5.1: Project appears to be an original concept"
    type: "ai_check"
    files_to_analyze: ["README.md", "settings.py"]
    per_file_char_limit: 6000
    total_context_char_limit: 12000
    prompt: >
      Assess if a BEGINNER project is an original idea or a direct tutorial clone. Look at the README description and project name in settings. Be generous.
      
      Scoring:
      - PASS: Appears to be an original concept or a customized/extended version of a common idea (e.g., "a blog for hikers", "a todo app with teams").
      - FAIL: Appears to be a direct, unmodified clone of a very common tutorial (e.g., the standard "Django Polls app", a basic "blog" with no unique features described).
      
      Output format:
      PASS|FAIL - short reason (e.g., "Appears to be a standard blog tutorial" or "Project describes a unique 'job board for graduates' concept").

      CONTEXT:
      ---
      {context}
      ---

  # --- R7: Proper Error Handling (0-1 pt) ---
  - name: "R7.1: Basic error handling is present in views"
    type: "ai_check"
    files_to_analyze: ["views.py"]
    per_file_char_limit: 8000
    total_context_char_limit: 8000
    prompt: >
      Review beginner Django views for basic error handling.
      Look for: (1) Use of try/except blocks for ORM calls that might fail (e.g., .get()), (2) Handling of non-existent objects (404s), (3) Validation checks (e.g., `serializer.is_valid()`).
      
      Scoring:
      - PASS: Basic error handling is present. Uses try/except, get_object_or_404, or checks .is_valid() before saving.
      - FAIL: No visible error handling. Bare .get() calls without try/except, no 404s, assumes data is always valid.
      
      Output format:
      PASS|FAIL - short reason
      Suggestions:
      - bullet list (only if FAIL)

      CONTEXT:
      ---
      {context}
      ---

  # --- R8: Provided API Documentation (0-1 pt) ---
  - name: "R8.1: API Documentation is provided"
    type: "ai_check"
    files_to_analyze: ["README.md", "urls.py"]
    per_file_char_limit: 6000
    total_context_char_limit: 12000
    prompt: >
      Check if API documentation is provided.
      Look for (1) an "API" or "Endpoints" section in the README, OR (2) setup for Swagger/Redoc in urls.py.
      
      Scoring:
      - PASS: Found either a clear API section in the README OR urls for an auto-generated doc (Swagger/Redoc).
      - FAIL: Found neither.
      
      Output format:
      PASS|FAIL - short reason

      CONTEXT:
      ---
      {context}
      ---